展示的时候，台式机、PC 和 tian 一起运行，确保万无一失！


考虑一下我们的任务需求：根据用户输入的歌词，推荐 k 首相似的歌曲给用户。这个问题可以抽象为，根据用户输入的歌词文档，返回歌曲库中与输入歌词文档最相似的 k 篇歌词文档给用户。因此，这里我们需要考虑的一个问题是，如何衡量两篇歌词文档之间的相似度。（箭头图）

目前我们还没有很好的方法能够直接衡量两篇歌词文档之间的相似度。但是，我们有很好的词向量工具 —— word2vec 来衡量两个词语之间的相似度。我们的想法是，通过某种方式组合词向量，进而得到文档向量，从而在向量空间中用某种距离度量的方法来衡量两篇文档的相似度。（箭头图）

下面我们将简要地介绍词向量 word2vec 以及组合词向量的工具 tfidf。



### 1. 简要介绍 word2vec 和 tfidf 

对于如何表示一个词语，一种很 naive 的想法是使用 one-hot 编码。但这种编码方法没有办法衡量两个词语之间的相似程度（两个词语之间的相似程度都是相同的）。word2vec 认为拥有相似上下文的词语之间是相似的，在词向量空间中表现为两个向量的余弦距离较小。 然后使用固定维度的实数向量来表示词语。

有了词向量后，我们能够衡量词语之间的相似度。但是，对于由词语构成的文档的相似度，我们要怎么度量呢？

这里一个很自然的想法是把文档里面每个词语的向量加起来，从而得到文档的向量。但是我们知道，文档中的每个词语不是一样重要的。某个词语在文档中出现的次数越多，同时在其它文档中出现的次数较少，那么我们就说这个词语是重要的。这就是 TF-IDF 的思想。即 TF-IDF 于词语在该文档中出现的次数成正比，与词语在其它文档中出现的次数成反比。

把 TF-IDF 作为文档中每个词语的权重，加权求和即可得到文档的向量表示。

### 2. 一些技术细节

- 清洗文本：把不是中文的字符全部置换成空格
- 分词：使用的是中文分词软件 jieba 
- TF-IDF：使用的是 gensim 库
- 相似度计算使用的是 KNN 算法